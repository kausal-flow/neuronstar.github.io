<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>人工神经网络方法解方程 &#8211; NEURONSTAR</title>
<meta name="description" content="数值方法解方程大多要一个把方程或者函数参数化，例如改写成差分方程，变成步长等等的函数。例如我们要解这样一个方程：

">
<meta name="keywords" content="">


<!-- Twitter Cards -->
<meta name="twitter:title" content="人工神经网络方法解方程">
<meta name="twitter:description" content="数值方法解方程大多要一个把方程或者函数参数化，例如改写成差分方程，变成步长等等的函数。例如我们要解这样一个方程：

">



<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://localhost:4000/images/logo.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="人工神经网络方法解方程">
<meta property="og:description" content="数值方法解方程大多要一个把方程或者函数参数化，例如改写成差分方程，变成步长等等的函数。例如我们要解这样一个方程：

">
<meta property="og:url" content="http://localhost:4000/science/ann-ode/">
<meta property="og:site_name" content="NEURONSTAR">





<link rel="canonical" href="http://localhost:4000/science/ann-ode/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="NEURONSTAR Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<!-- Webfonts -->
<script src="https://use.edgefonts.net/source-sans-pro:n2,i2,n3,i3,n4,i4,n6,i6,n7,i7,n9,i9;source-code-pro:n4,n7;volkhov.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
  <script src="http://localhost:4000/assets/js/vendor/html5shiv.min.js"></script>
  <script src="http://localhost:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>


<!-- MathJax -->
<script src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">

</head>

<body id="post">

<div class="navigation-wrapper">
	<nav role="navigation" id="site-nav" class="animated drop">
	    <ul>
      
		    
		    <li><a href="http://localhost:4000/" >Home</a></li>
		  
		    
		    <li><a href="http://localhost:4000/about/" >About</a></li>
		  
		    
		    <li><a href="http://localhost:4000/articles" >Articles</a></li>
		  
		    
		    <li><a href="http://localhost:4000/resources" >Resources</a></li>
		  
		    
		    <li><a href="http://neuronstar.xyz/comp-neurosci-map" target="_blank">Map of Neuroscience</a></li>
		  
	    </ul>
	</nav>
</div><!-- /.navigation-wrapper -->

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->

<header class="masthead">
	<div class="wrap">
      
  		<a href="http://localhost:4000/" class="site-logo" rel="home" title="NEURONSTAR"><img src="http://localhost:4000/images/logo.png" width="200" height="200" alt="NEURONSTAR logo" class="animated fadeInDown"></a>
      
      <h1 class="site-title animated fadeIn"><a href="http://localhost:4000/">NEURONSTAR</a></h1>
		<h2 class="site-description animated fadeIn" itemprop="description">Neuroscience and Complex Systems</h2>
	</div>
</header><!-- /.masthead -->

<div class="js-menu-screen menu-screen"></div>


<div id="main" role="main">
  <article class="hentry">
    
    <div class="entry-wrapper">
      <header class="entry-header">
        <ul class="entry-tags">
          
        </ul>
        
          <h1 class="entry-title">人工神经网络方法解方程</h1>
        
      </header>
      <footer class="entry-meta">
        
        
          <img src="http://localhost:4000/images/authors/octomiao.jpg" class="bio-photo" alt="OctoMiao bio photo"></a>
        
        <span class="author vcard">By <span class="fn">OctoMiao</span></span>
        <span class="entry-date date published"><time datetime="2015-03-22T00:00:00-06:00"><i class="fa fa-calendar-o"></i> March 22, 2015</time></span>
        <span class="entry-date date modified"><time datetime="2015-08-31"><i class="fa fa-pencil"></i> August 31, 2015</time></span>
        <span class="entry-comments"><i class="fa fa-comment-o"></i> <a href="#disqus_thread">Comment</a></span>
        
        
      </footer>
      <div class="entry-content">
        <p>数值方法解方程大多要一个把方程或者函数参数化，例如改写成差分方程，变成步长等等的函数。例如我们要解这样一个方程：</p>

<script type="math/tex; mode=display">\frac{dy(t)}{dt} = -y(t),</script>

<p>其中初始条件 $y(0)=1$ 已知。</p>

<p>一种普遍的手段是，我们可以把其中的待解函数参数化为 $y(t,\{n_i\})$，然后把方程重新写成</p>

<script type="math/tex; mode=display">\frac{dy(t, \{n_i\})}{dt}  + y(t,\{n_i\}) = 0,</script>

<p>其中 $\{n_i\}$ 是用来参数化这个函数的参数。有了这个式子，我们会联想到最小二乘法。也就是说，如果我们的参数化完全正确的话，我们应该得到方程的左边的两项之和总是零，也就是 $\frac{dy(t, \{n_i\})}{dt}$ 和 $- y(t,\{n_i\}) $ 的没有偏离，即</p>

<script type="math/tex; mode=display">\text{waste} = \frac{dy(t, \{n_i\})}{dt}  + y(t,\{n_i\}) ,</script>

<p>这个量总是零。然而数值上来讲，我们有一个更加简单的方法来让这个量在任意的 $t$ 总是零，方法就是借助最小二乘法的思路，利用一个凹函数，</p>

<script type="math/tex; mode=display">\text{cost} = \int dt ( \frac{dy(t, \{n_i\})}{dt}  + y(t,\{n_i\}) )^2.</script>

<p>倘若 $\text{cost} = 0$，我们推断上面定义的 $\text{waste}$ 函数在任意的 $t$ 都为零。</p>

<h2 id="section">人工神经网络参数化</h2>

<p>下面我们引入一种与人工神经网络相关的参数化方法，然后通过定义一个代价，最后最小化这个代价从而获得参数化中的各种参数，从而解出函数。</p>

<p>人的神经元有一个特点就是，存在激活和不激活两种状态，激活的话信号传递，不激活的话，信号被毙掉。数学上我们可以通过一个类似阶梯的函数来模拟这个行为，例如：</p>

<figure>
  <figcaption>
阶梯函数图像，可以挑选出某些参数值。
</figcaption>
  <p><img src="http://localhost:4000/images/posts/annode/Dirac_distribution_CDF.png" alt="" /></p>
</figure>

<p>然而数值上来讲，这个函数有个非常大的缺点，就是导数不连续。尤其是对于我们想要解一个微分方程来说，用来参数化的函数里面包含导数不连续的部分，那是非常不方便的。</p>

<p>所以我们会选取一个导数连续但是也具有类似行为的函数，比如一个 sigmoid 函数，</p>

<script type="math/tex; mode=display">\text{sigmoid}(t) = \frac{1}{1+e^{-t}}.</script>

<p>这个函数的图像是</p>

<figure>
  <figcaption>
sigmoid 函数，也具有挑选出某些参数值的功能。
</figcaption>
  <p><img src="http://localhost:4000/images/posts/annode/Logistic-curve.png" alt="" /></p>
</figure>

<p>这个函数有个非常大的优势，就是如果我们把要求解的函数利用这个参数化，所有的导数全是可以解析求解的，对于数值计算是一个福音。</p>

<p>我们可以模拟神经元可以被激活这种性质，来挑选出一些我们想要的参数，这个示例中用到的就是 sigmoid 函数。我们挑选一组参数 ${v_k}$, ${w_k}$ 和 ${u_k}$，对于一个函数 $y(t)$，我们可以用下面的方法来参数化，</p>

<script type="math/tex; mode=display">y(t)= y(0)+t \sum_k v_k f(t w_k+u_k).</script>

<p>这样做的原因是在 $t=0$ 时，我们确保参数化的函数满足给定的初始条件（$t=0$ 时 $t \sum_k v_k f(t w_k+u_k)=0$）。而 $f(x)$ 使我们的启动函数，这里我们用 sigmoid 函数。也就是说，在某个时刻 $t_i$，当参量 $t w_k+u_k$ 比较大的时候，我们输入的 $t$ 才会起作用，否则我们的输入 $t$ 被压制。</p>

<p>$w_k$ 是对启动函数的缩放，$u_k$ 是对启动函数的平移，而 $v_k$ 的作用是放大缩小函数值。可以设想，当我们的参数足够多的时候，我们可以用这个参数化来组成任何连续函数。</p>

<h2 id="cost">cost</h2>

<p>那么如何得到这些参数的值呢？我们一开始定义了这样一个量，</p>

<script type="math/tex; mode=display">\text{cost} = \int dt ( \frac{dy(t, \{n_i\})}{dt}  + y(t,\{n_i\}) )^2.</script>

<p>我们想要做的是得到什么的参数可以有 $\text{cost} = 0$ 的结果。</p>

<p>然而我们不想做积分，所以自然的选择是离散化，选择一个序列 ${t_i}$，并且考虑</p>

<script type="math/tex; mode=display">\text{cost} = \sum_j \left(\frac{dy(t_j, \{n_i\})}{dt}  + y(t_j,\{n_i\}) \right)^2.</script>

<p>当我们选到一组参数使得这个量为零的时候，我们的参数就是函数的正确的参数化（在当前的初始条件下的）。</p>

<p>所以我们就把一个解方程问题转换成了一个最小化问题了，因为 $\text{cost}$ 的值越小，说明我们的参数就越接近满足</p>

<script type="math/tex; mode=display">\frac{dy(t, \{n_i\})}{dt}  + y(t,\{n_i\}) = 0,</script>

<p>当然是在一个特定初始条件下，这里我们的初始条件是 $y(0)=1$。</p>

<p>剩下的部分，就无需我多说了，只需要用任何你想要的方法，来把 $\text{cost}$ 最小化，得到的参数值们 $\{v_k\}$, $\{w_k\}$ 和 $\{u_k\}$ 带回到函数的参数化</p>

<script type="math/tex; mode=display">y(t)= y(0)+t \sum_k v_k f(t w_k+u_k),</script>

<p>这样我们就有了这个微分方程在当前初始条件下的解。</p>

<p>上面我们离散化 cost 的过程中，</p>

<script type="math/tex; mode=display">\text{cost} = \sum_j \frac{dy(t_j, \{n_i\})}{dt}  + y(t_j,\{n_i\}) )^2.</script>

<p>里面的每一个时间点的输入都是一次对神经网络的训练，如同人的学习一样，经过多次训练，我们就可以掌握方程的这种行为。而所学习到的信息，存在了神经网络的参数中（也就是网络的结构中）。</p>

<h2 id="section-1">代码举例</h2>

<p>以下是这个问题的 Python 代码，<a href="http://nbviewer.ipython.org/github/NeuPhysics/sync-de-solver/blob/master/ipynb/neural-net.ipynb">这里有一份带有全面说明的 IPython Notebook</a>。</p>

<figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">from</span> <span class="nn">scipy.special</span> <span class="kn">import</span> <span class="n">expit</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="kn">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">cost</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
    <span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">v</span><span class="p">)</span>   <span class="c"># Don't know why but np.asarray(v) doesn't work here.</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">u</span><span class="p">)</span>

    <span class="n">fvec</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">trigf</span><span class="p">(</span><span class="n">t</span><span class="o">*</span><span class="n">w</span> <span class="o">+</span> <span class="n">u</span><span class="p">)</span> <span class="p">)</span>  <span class="c"># This is a vector!!!</span>
    <span class="n">yt</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span> <span class="p">(</span> <span class="n">t</span> <span class="o">*</span> <span class="n">v</span> <span class="o">*</span> <span class="n">fvec</span>  <span class="p">)</span>  <span class="c"># For a given t, this calculates the value of y(t), given the parameters, v, w, u.</span>
    <span class="k">return</span>  <span class="p">(</span> <span class="n">np</span><span class="o">.</span><span class="nb">sum</span> <span class="p">(</span><span class="n">v</span><span class="o">*</span><span class="n">fvec</span> <span class="o">+</span> <span class="n">t</span> <span class="o">*</span> <span class="n">v</span><span class="o">*</span> <span class="n">fvec</span> <span class="o">*</span> <span class="p">(</span> <span class="mi">1</span> <span class="o">-</span>  <span class="n">fvec</span>  <span class="p">)</span> <span class="o">*</span> <span class="n">w</span> <span class="p">)</span> <span class="o">+</span> <span class="n">yt</span> <span class="p">)</span>   <span class="o">**</span> <span class="mi">2</span>

<span class="k">def</span> <span class="nf">trigf</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="c">#return 1/(1+np.exp(-x)) #</span>
    <span class="k">return</span> <span class="n">expit</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">costTotal</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">t</span><span class="p">):</span>
    <span class="n">t</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">t</span><span class="p">)</span>
    <span class="n">costt</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">temp</span> <span class="ow">in</span> <span class="n">t</span><span class="p">:</span>
        <span class="n">costt</span> <span class="o">=</span> <span class="n">costt</span> <span class="o">+</span> <span class="n">cost</span><span class="p">(</span><span class="n">v</span><span class="p">,</span><span class="n">w</span><span class="p">,</span><span class="n">u</span><span class="p">,</span><span class="n">temp</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">costt</span>

<span class="n">costTotalF</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">costTotal</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">)[</span><span class="mi">0</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">)[</span><span class="mi">1</span><span class="p">],</span><span class="n">np</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">3</span><span class="p">)[</span><span class="mi">2</span><span class="p">],</span><span class="n">tlin</span><span class="p">)</span>

<span class="n">initGuess</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="mi">30</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">costTotalF</span><span class="p">,</span><span class="n">initGuess</span><span class="p">,</span><span class="n">method</span><span class="o">=</span><span class="s">"SLSQP"</span><span class="p">)</span></code></pre></figure>

<h2 id="section-2">为什么找这么多麻烦</h2>

<p>显然，上面的例子不仅可以用任何差分方法来解，而且有解析解。我们为什么要找这么多麻烦来做这样的参数化呢？</p>

<p>或许我们要解决一个当前的状态依赖于全空间中的所有点的问题，这时候，我们就不好再用差分法了，因为要解出当前点我们需要知道所有的其他的点。上面这种一次性解出整个方程的方法就变得更加方便，因为我们解出方程并不是依赖于获得其他地方的信息，而是通过人工神经网络一次性猜到所有空间点的解。</p>

<p>不过，本文开始讲的这种方法具有非常好的普适性。我们使用 ANN 是因为 Cybenko 在 1989 年证明了一个 sigmoid 可以作为很好的 universal approximator 来处理任意的 measurable functions。<sup id="fnref:cybenko1989"><a href="#fn:cybenko1989" class="footnote">1</a></sup></p>

<p>现在我们重新思考一下这个方法的普适性。倘若我们有个系统，可以用傅里叶展开，而且所幸我们只需要展开中的前 100 项就可以很好的来估算整个系统了。那么我们就把这个展开式写出来，然后取前 100 项，这样一样定义一个 cost，一样来找到使得 cost 最小化的参数，就可以求出傅里叶展开的系数们了。</p>

<p>不过这个方法是不是足够有效，取决于我们所挑选的参数化形式。Kolmogorov 证明过如果选的足够好，我们可以用<strong>有限个</strong>与 y 无关的函数来精确的还原 y。</p>

<div class="footnotes">
  <ol>
    <li id="fn:cybenko1989">
      <p><a href="http://numsoltun.readthedocs.org/ann.html#universal-approximators">Click here to find out the statement.</a> <a href="#fnref:cybenko1989" class="reversefootnote">&#8617;</a></p>
    </li>
  </ol>
</div>

        
          <div id="disqus_thread"></div><!-- /#disqus_thread -->
          
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'neuronstar'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'https://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        
      </div><!-- /.entry-content -->
    </div><!-- /.entry-wrapper -->
    <nav class="pagination" role="navigation">
      
        <a href="http://localhost:4000/til/til/" class="btn" title="Today I Learned">Previous</a>
      
      
        <a href="http://localhost:4000/science/echolocation/" class="btn" title="回声定位">Next</a>
      
    </nav><!-- /.pagination -->
  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo" class="entry-wrapper">
    

<span>&copy; 2016 <a href="" style="text-decoration: underline;" target="_blank">HLLM</a>. Powered by <a href="http://jekyllrb.com" style="text-decoration: underline;" rel="nofollow">Jekyll</a> using the <a href="https://mademistakes.com/work/so-simple-jekyll-theme/" style="text-decoration: underline;" rel="nofollow">So Simple Theme</a>.</span>
<div class="social-icons">
	
	
	
	
	
	
	
	<a href="https://github.com/neuronstar" title="HLLM on Github" target="_blank"><i class="fa fa-github-square fa-2x"></i></a>
	
  
	
  <a href="http://localhost:4000/feed.xml" title="Atom/RSS feed"><i class="fa fa-rss fa-2x"></i></a>
</div><!-- /.social-icons -->

  </footer>
</div><!-- /.footer-wrapper -->

<script type="text/javascript">
  var BASE_URL = 'http://localhost:4000';
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>


<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 'https://www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-61051776-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = 'https://stats.g.doubleclick.net/dc.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>



</body>
</html>
