<!doctype html>
<!--[if lt IE 7]><html class="no-js lt-ie9 lt-ie8 lt-ie7" lang="en"> <![endif]-->
<!--[if (IE 7)&!(IEMobile)]><html class="no-js lt-ie9 lt-ie8" lang="en"><![endif]-->
<!--[if (IE 8)&!(IEMobile)]><html class="no-js lt-ie9" lang="en"><![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en"><!--<![endif]-->
<head>
<meta charset="utf-8">
<title>01.Introductions (Review) and Several Preliminary Statistical Methods &#8211; NEURONSTAR</title>
<meta name="description" content="Review

">
<meta name="keywords" content="">


<!-- Twitter Cards -->
<meta name="twitter:title" content="01.Introductions (Review) and Several Preliminary Statistical Methods">
<meta name="twitter:description" content="Review

">



<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://localhost:4000/images/logo.png">

<!-- Open Graph -->
<meta property="og:locale" content="en_US">
<meta property="og:type" content="article">
<meta property="og:title" content="01.Introductions (Review) and Several Preliminary Statistical Methods">
<meta property="og:description" content="Review

">
<meta property="og:url" content="http://localhost:4000/elements-of-statistical-learning/01.statistical-learning-theory/">
<meta property="og:site_name" content="NEURONSTAR">





<link rel="canonical" href="http://localhost:4000/elements-of-statistical-learning/01.statistical-learning-theory/">
<link href="http://localhost:4000/feed.xml" type="application/atom+xml" rel="alternate" title="NEURONSTAR Feed">

<!-- https://t.co/dKP3o1e -->
<meta name="HandheldFriendly" content="True">
<meta name="MobileOptimized" content="320">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<!-- For all browsers -->
<link rel="stylesheet" href="http://localhost:4000/assets/css/main.css">
<link rel="stylesheet" href="http://localhost:4000/assets/css/style.css">
<!-- Webfonts -->
<script src="https://use.edgefonts.net/source-sans-pro:n2,i2,n3,i3,n4,i4,n6,i6,n7,i7,n9,i9;source-code-pro:n4,n7;volkhov.js"></script>

<meta http-equiv="cleartype" content="on">

<!-- HTML5 Shiv and Media Query Support -->
<!--[if lt IE 9]>
  <script src="http://localhost:4000/assets/js/vendor/html5shiv.min.js"></script>
  <script src="http://localhost:4000/assets/js/vendor/respond.min.js"></script>
<![endif]-->

<!-- Modernizr -->
<script src="http://localhost:4000/assets/js/vendor/modernizr-2.7.1.custom.min.js"></script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
});
</script>
<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({ TeX: { extensions: ["color.js","cancel.js", "AMSmath.js", "AMSsymbols.js"] }});
  </script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Register.StartupHook("TeX Jax Ready",function () {
    MathJax.Hub.Insert(MathJax.InputJax.TeX.Definitions.macros,{
      cancel: ["Extension","cancel"]
      });
   });
   </script>
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      }
    });
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    tex2jax: {
      processEscapes: true
    }
  });
</script>
  <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    TeX: {
      Macros: {
        overlr: ['\\overset\\leftrightarrow{\#1}',1],
        overl: ['\\overset\leftarrow{\#1}',1],
        overr: ['\\overset\rightarrow{\#1}',1],
        bra: ['\\left\\langle \#1\\right|',1],
        ket: ['\\left| \#1\\right\\rangle',1],
        braket: ['\\langle \#1 \\mid \#2 \\rangle',2],
        avg: ['\\left< \#1 \\right>',1],
        slashed: ['\\cancel{\#1}',1],
        bold: ['\\boldsymbol{\#1}',1],
        sech: ['\\operatorname{sech}{\#1}',1],
        csch: ['\\operatorname{csch}{\#1}',1]
      }
    }
  });
  </script>
<!-- MathJax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>


<!-- Icons -->
<!-- 16x16 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.ico">
<!-- 32x32 -->
<link rel="shortcut icon" href="http://localhost:4000/favicon.png">
<!-- 57x57 (precomposed) for iPhone 3GS, pre-2011 iPod Touch and older Android devices -->
<link rel="apple-touch-icon-precomposed" href="http://localhost:4000/images/apple-touch-icon-precomposed.png">
<!-- 72x72 (precomposed) for 1st generation iPad, iPad 2 and iPad mini -->
<link rel="apple-touch-icon-precomposed" sizes="72x72" href="http://localhost:4000/images/apple-touch-icon-72x72-precomposed.png">
<!-- 114x114 (precomposed) for iPhone 4, 4S, 5 and post-2011 iPod Touch -->
<link rel="apple-touch-icon-precomposed" sizes="114x114" href="http://localhost:4000/images/apple-touch-icon-114x114-precomposed.png">
<!-- 144x144 (precomposed) for iPad 3rd and 4th generation -->
<link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/images/apple-touch-icon-144x144-precomposed.png">

<!-- <script src="http://localhost:4000/assets/js/readmorejs/readmore.min.js"></script>

<script type="text/javascript">
$('div').readmore({
      speed: 100,
      collapsedHeight: 50,
      moreLink: "<a href='#'>More</a>",
      lessLink: "<a href='#'>Less</a>"
    });
</script> -->

</head>

<body id="post">

<div class="navigation-wrapper">
	<nav role="navigation" id="site-nav" class="animated drop">
	    <ul>
      
		    
		    <li><a href="http://localhost:4000/" >Home</a></li>
		  
		    
		    <li><a href="http://localhost:4000/about/" >About</a></li>
		  
		    
		    <li><a href="http://localhost:4000/club" >Reading Club</a></li>
		  
		    
		    <li><a href="http://localhost:4000/articles" >Articles</a></li>
		  
		    
		    <li><a href="http://localhost:4000/resources" >Resources</a></li>
		  
		    
		    <li><a href="http://neuronstar.cc/comp-neurosci-map" target="_blank">Map of Neuroscience</a></li>
		  
		    
		    <li><a href="https://zhuanlan.zhihu.com/neuronsketch" target="_blank">Sparks and Spikes</a></li>
		  
	    </ul>
	</nav>
</div><!-- /.navigation-wrapper -->

<!--[if lt IE 9]><div class="upgrade"><strong><a href="http://whatbrowser.org/">Your browser is quite old!</strong> Why not upgrade to a different browser to better enjoy this site?</a></div><![endif]-->

<header class="masthead">
	<div class="wrap">
      
  		<a href="http://localhost:4000/" class="site-logo" rel="home" title="NEURONSTAR"><img src="http://localhost:4000/images/logo.png" width="200" height="200" alt="NEURONSTAR logo" class="animated fadeInDown"></a>
      
      <h1 class="site-title animated fadeIn"><a href="http://localhost:4000/">NEURONSTAR</a></h1>
		<h2 class="site-description animated fadeIn" itemprop="description">Neuroscience and Complex Systems</h2>
	</div>
</header><!-- /.masthead -->

<div class="js-menu-screen menu-screen"></div>


<div id="main" role="main">
  <article class="hentry">
    
    <div class="entry-wrapper">
      <header class="entry-header">
        <ul class="entry-tags">
          
        </ul>
        
          <h1 class="entry-title">01.Introductions (Review) and Several Preliminary Statistical Methods</h1>
        
      </header>
      <footer class="entry-meta">
        <hr>
        

        <span><i class="fa fa-map-signs"></i> <a href="http://localhost:4000/elements-of-statistical-learning/00.The-Elements-of-Statistical-Learning/">References [<i class="fa fa-link" aria-hidden="true"></i>]</a>:<br>
          <a style="padding-left:1.1em;"> The Elements of Statistical Learning </a>
        </span>
        


        <span style="padding-top:1em;margin-bottom:1em;">
          Live chat with others.

      <button class="js-gitter-toggle-chat-button btn" style="margin-top:1em;"><i class="fa fa-comments" aria-hidden="true"></i> Toggle Chat</button>

      </span>




        
        
          <img src="http://localhost:4000/images/authors/octomiao.jpg" class="bio-photo" alt="OctoMiao bio photo"></a>
        
        <span class="author vcard">By <span class="fn">OctoMiao</span></span>
        <span class="entry-date date published"><time datetime="2016-07-06T00:00:00+00:00"><i class="fa fa-calendar-o"></i> July 06, 2016</time></span>
        
        
        <span class="social-share-twitter">
          <a href="https://github.com/emptymalei" title="Author's Github"><i class="fa fa-github"></i> Author's GitHub</a>
        </span>
        
        
        <span class="social-share-twitter">
          <a href="https://github.com/neuronstar/elements-of-statistical-learning" title="Author's Github"><i class="fa fa-pencil"></i>  Edit on GitHub</a>
        </span>
        
        <span class="entry-comments"><i class="fa fa-comment-o"></i> <a href="#disqus_thread">Comment</a></span>
        
        








      </footer>
      <div class="entry-content">
        <!--  -->
        <h2 id="review">Review</h2>

<p><strong>Skeleton notes</strong></p>

<h3 id="abbreviations">Abbreviations</h3>

<ol>
  <li>MSE: mean squared error</li>
  <li>EPE: expected prediction error</li>
  <li>RSS: sum of squares</li>
</ol>

<h3 id="notations">Notations</h3>

<p>Fonts:</p>

<ol>
  <li>Vectors or scalars are denoted by italic math font $X$.</li>
  <li>Components of vectors are denoted by subscripts $X_i$.</li>
  <li>Matrix is denoted by math bold font $\mathbf X$.</li>
</ol>

<p>Symbols</p>

<ol>
  <li>$X$ for input variables;</li>
  <li>$Y$ for quantitative output;</li>
  <li>$G$ for qualitative output;</li>
  <li>$\hat {}$ for prediction.</li>
</ol>

<h3 id="least-squares-and-nearest-neighbors">Least Squares and Nearest Neighbors</h3>

<h4 id="least-squares">Least Squares</h4>

<p>Least square model:</p>

<script type="math/tex; mode=display">\hat Y = X^T \hat \beta.</script>

<p>Residual sum of squares (RSS):</p>

<script type="math/tex; mode=display">\mathrm{RSS}(\beta) = (\mathbf y - \mathbf X \beta)^{\mathrm T} (\mathbf y - \mathbf X \beta).</script>

<p>The parameters we need is the set that minimizes RSS, which requires</p>

<script type="math/tex; mode=display">\frac{d}{d\beta} \mathrm{RSS} = 0.</script>

<p>So we can solve the parameters easily.</p>

<h4 id="nearest-neighbor">Nearest-Neighbor</h4>

<ol>
  <li>For input data $x$, calculate the Euclidean distance between $x$ and other input data $x_j$.</li>
  <li>Choose the $k$ nearest neighbors based on the distance.</li>
  <li>Output prediction is determined by average of the corresponding outputs of the selected inputs.
<script type="math/tex">\hat Y = \frac{1}{k} \sum_{N_k} y_i.</script></li>
</ol>

<p class="notes--info">For the calculation of distance, metric must be implemented. The book used examples of Euclidean metric. Another metric that can be inspiring is the hyperbolic space. I talked about this in <a href="https://reading-club.github.io/5weekplus/week2.html">our reading club</a>.</p>

<h4 id="for-which-scenario">For Which Scenario</h4>

<ol>
  <li>Least squares: Gaussian-like data set;</li>
  <li>Nearest-Neighbor: mixture of Gaussians.</li>
</ol>

<p class="notes--warning">Mixture of Gaussians can be described by generative model. I am not really sure what that is. It seems to me that the final data is basically generated from Gaussians of different parameters which are generated randomly.</p>

<h2 id="statistical-decision-theory">Statistical Decision Theory</h2>

<ol>
  <li>Given input $X$ and output $Y$;</li>
  <li>Following a joint distribution $\mathrm{Pr}(X,Y)$;</li>
  <li>Based on input and output, we look for a function that predicts the behavior, i.e., $\hat Y = f(X)$;</li>
  <li>How well the prediction is is defined by squared error loss $L(Y,\hat Y) = (Y-\hat Y)^2$.</li>
  <li>With the distribution, we predict the expected prediction error (EPE) as
<script type="math/tex">\mathrm{EPE}(f) = E[ ( Y- \hat Y )^2 ] = \int (y - f(x))^2 \mathrm{Pr}(dx, dy).</script></li>
  <li>The book derived that the best prediction is $f(x) = E(Y\vert X=x)$.</li>
  <li>Different loss functions lead to different EPE’s.</li>
</ol>

<p class="notes--warning">Question: Can we simply solve the probability distribution and find out the function of prediction? The conclusion says the best prediction of $Y$ is the conditional mean. Is it effectively solving $Y$ from the probability distribution?</p>

<h3 id="nearest-neighbor-1">Nearest-Neighbor</h3>

<ol>
  <li>The best prediction based on EPE is conditional mean, Eq. 2.13;</li>
  <li>Both $k$ nearest neighbor and linear regression fits into this framework;</li>
  <li>Additive models: basically turn the linear $x^T\beta$ into a function of $f_j(X_j)$. The summation still holds.</li>
  <li>The best prediction based on expectation only is conditional median.</li>
  <li>Categorical variable $G$ also follows the same paradigm but with different loss function.</li>
  <li>A choice of loss function for categorical case is a matrix. It has to be a matrix because we have to specify penalties a given prediction class compared to the output class. The dimension of this matrix should be the number of categories. It is rank 2.</li>
</ol>

<div class="notes--info">
  <p>Some comments on this section:</p>

  <ol>
    <li>0 neighbor indicates an exact classification for the sample data but without the implementation of expectation values at each point since there is only one value at that point in one set of sample data;</li>
    <li>$k$ nearest neighbor assumed that expectation around a small patch of a point is identical to expectation at the exact point with the corresponding distribution.</li>
    <li>In Monte Carlo method, calculation of volume in high dimension converges very slowly. The reason is that we need a very large number of sampling points since the dimension is high. The procedure is multiplicative. The same thing might happen here. $k$ nearest neighbor is basically some kind of averaging procedure of the volume density. It requires a large number of sample data points to perform an fairly accurate average.</li>
    <li>The linear regression is basically a first order Taylor expansion of the approximator $f(x)$. $f(x) = x^T\beta$.</li>
  </ol>
</div>

<h2 id="local-methods-in-high-dimensions">Local Methods in High Dimensions</h2>

<ol>
  <li>Curse of high dimensions: edge length of a cube of volume $r$ is $e_p(r) = r^{1/p}$. An extreme example: $(10^{-10})^{1/10} =0.1$.</li>
  <li>Small volume leads to high variance.</li>
  <li>Homogeneous sampling doesn’t work in high dimensions. Since most points will fall near the edges.
    <figure>
      <p><img src="../assets/00.The-Elements-of-Statistical-Learning/10dsphere-volume-vs-radius.png" alt="" /></p>
      <figcaption>
        <p>Volume of 10D sphere as a function of radius.</p>
      </figcaption>
    </figure>
  </li>
  <li>Requires huge number of sample points in high dimensions.</li>
</ol>

<h2 id="statistical-models-supervised-learning-and-function-approximation">Statistical Models, Supervised Learning and Function Approximation</h2>

<h3 id="joint-distribution">Joint Distribution</h3>

<p class="notes--warning">I didn’t not get the point of this subsection. It seems that the authors are talking about whether it is proper to assume the relation between input and output is deterministic.</p>

<h3 id="supervised-learning">Supervised Learning</h3>

<ol>
  <li>learn by example.</li>
</ol>

<h3 id="function-approximation">Function Approximation</h3>

<ol>
  <li>Linear model;</li>
  <li>Function as basis (Eq. 2.30): $f_\theta(x) = \sum h_k(x)\theta_k$.</li>
  <li>Examples of function bases are Fourier expansions, sigmoid, etc.</li>
  <li>Learning through minimizing sum of squares (RSS), or maximum likelihood estimation, etc.</li>
  <li>Maximum likelihood estimation:
    <ol>
      <li>Likelihood: $L(\theta) = \sum_{i=1}^N \log \mathrm{Pr}_\theta (y_i)$;</li>
      <li>Maximized it (“probability of the observed sample is largest”)</li>
      <li>Minimizing RSS is equivalent to maximum likelihood estimation. Eq. 2.35.</li>
    </ol>
  </li>
</ol>


        <nav class="pagination" role="navigation">
          
            <a href="http://localhost:4000/elements-of-statistical-learning/00.The-Elements-of-Statistical-Learning/" class="btn" title="00.The Elements of Statistical Learning Reading Club">Previous</a>
          
          
        </nav><!-- /.pagination -->

        
          <div id="disqus_thread"></div><!-- /#disqus_thread -->
          
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = 'neuronstar'; // required: replace example with your forum shortname

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function () {
        var s = document.createElement('script'); s.async = true;
        s.type = 'text/javascript';
        s.src = 'https://' + disqus_shortname + '.disqus.com/count.js';
        (document.getElementsByTagName('HEAD')[0] || document.getElementsByTagName('BODY')[0]).appendChild(s);
    }());
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        
      </div><!-- /.entry-content -->
    </div><!-- /.entry-wrapper -->

  </article>
</div><!-- /#main -->

<div class="footer-wrapper">
  <footer role="contentinfo" class="entry-wrapper">
    

<span>&copy; 2017 <a href="" style="text-decoration: underline;" target="_blank">HLLM</a>. Powered by <a href="http://jekyllrb.com" style="text-decoration: underline;" rel="nofollow">Jekyll</a>. Theme based on <a href="https://mademistakes.com/work/so-simple-jekyll-theme/" style="text-decoration: underline;" rel="nofollow">So Simple</a>. <a href="http://localhost:4000//typography" style="text-decoration: underline;"><i class="fa fa-indent" aria-hidden="true"></i></a></span>
<div class="social-icons">
	
	
	
	
	
	
	
	<a href="https://github.com/neuronstar" title="HLLM on Github" target="_blank"><i class="fa fa-github-square fa-2x"></i></a>
	
  
	
  <a href="http://localhost:4000/feed.xml" title="Atom/RSS feed"><i class="fa fa-rss fa-2x"></i></a>
</div><!-- /.social-icons -->

  </footer>
</div><!-- /.footer-wrapper -->

<script type="text/javascript">
  var BASE_URL = 'http://localhost:4000';
</script>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.9.1/jquery.min.js"></script>
<script>window.jQuery || document.write('<script src="http://localhost:4000/assets/js/vendor/jquery-1.9.1.min.js"><\/script>')</script>
<script src="http://localhost:4000/assets/js/scripts.min.js"></script>


<!-- Asynchronous Google Analytics snippet -->
<script>
  var _gaq = _gaq || [];
  var pluginUrl =
 'https://www.google-analytics.com/plugins/ga/inpage_linkid.js';
  _gaq.push(['_require', 'inpage_linkid', pluginUrl]);
  _gaq.push(['_setAccount', 'UA-61051776-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = 'https://stats.g.doubleclick.net/dc.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();
</script>


<script>
  ((window.gitter = {}).chat = {}).options = {
    room: 'neuronstar/spiking-neuron-models',
    activationElement: false
  };
</script>
<script src="https://sidecar.gitter.im/dist/sidecar.v1.js" async defer></script>


</body>
</html>
